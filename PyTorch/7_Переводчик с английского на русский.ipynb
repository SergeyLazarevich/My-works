{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOifL1pgqt_a"
      },
      "source": [
        "# Переводчик с английского на русский"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ml7Gdt_9q2pZ"
      },
      "source": [
        "### 1. Переписать загрузку данных с python функций на Dataset и Dataloader и применить сеть с attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0dOcypQNrG6J"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Di79ibOku-ix"
      },
      "outputs": [],
      "source": [
        "data_path_ru = '/content/drive/Othercomputers/Мое устройство Компьютер/Google.Disk/Colab Notebooks/data/rus-eng/rus.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dkylh1IUCfr6"
      },
      "outputs": [],
      "source": [
        "class LipsDataset(torch.utils.data.Dataset):\n",
        "    \n",
        "    def __init__(self, data_path, num_samples = 300):\n",
        "        # loading data\n",
        "        self.input_texts = []\n",
        "        self.target_texts = []\n",
        "\n",
        "        input_vocab = set()\n",
        "        output_vocab = set()\n",
        "\n",
        "        with open(data_path, 'r', encoding='utf-8') as f:\n",
        "            lines = f.read().split('\\n')\n",
        "\n",
        "        for line in lines[: min(num_samples, len(lines) - 1)]:\n",
        "            input_text, target_text, _ = line.split('\\t')\n",
        "            target_text = '\\t' + target_text + '\\n'\n",
        "            self.input_texts.append(input_text)\n",
        "            for word in input_text.split():\n",
        "                input_vocab.add(word.strip())\n",
        "            self.target_texts.append(target_text)\n",
        "            for word in target_text.split():\n",
        "                output_vocab.add(word.strip())\n",
        "            \n",
        "        self.input_vocab2index = {word: i+2 for i, word in enumerate(input_vocab)}\n",
        "        self.output_vocab2index = {word: i+2 for i, word in enumerate(output_vocab)}\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        return self.tensorsFromSent(self.input_texts[index], self.target_texts[index])\n",
        "\n",
        "    def indexesFromSentence(self, sentence, vocab):\n",
        "        return [vocab.get(word.strip(), 0) for word in sentence.split(' ')]\n",
        "\n",
        "    def tensorFromSentence(self, sentence, vocab):\n",
        "        indexes = self.indexesFromSentence(sentence, vocab)\n",
        "        indexes.append(1)\n",
        "        return torch.tensor(indexes, dtype=torch.long).view(-1, 1)\n",
        "\n",
        "\n",
        "    def tensorsFromSent(self, input_sentences, output_sentences):\n",
        "        input_tensor = self.tensorFromSentence(input_sentences, self.input_vocab2index)\n",
        "        target_tensor = self.tensorFromSentence(output_sentences, self.output_vocab2index)\n",
        "        return (input_tensor, target_tensor)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_texts)\n",
        "\n",
        "    def len_target(self):\n",
        "        return len(self.output_vocab2index)\n",
        "\n",
        "    def len_input(self):\n",
        "        return len(self.input_vocab2index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xzyEMVxiXpwN"
      },
      "outputs": [],
      "source": [
        "# Собираем из текстов токены\n",
        "num_samples = 300\n",
        "dataset = LipsDataset(data_path_ru, num_samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-qNjG2jW4RZd"
      },
      "outputs": [],
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size)\n",
        "\n",
        "\n",
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=10):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        #output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "loVFK4_o5xIp"
      },
      "outputs": [],
      "source": [
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=10):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[0]])\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    for di in range(target_length):\n",
        "        decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "            decoder_input, decoder_hidden, encoder_outputs)\n",
        "        topv, topi = decoder_output.topk(1)\n",
        "        decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "        loss += criterion(decoder_output, target_tensor[di])\n",
        "        if decoder_input.item() == 1:\n",
        "            break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHhmhZ_951FB",
        "outputId": "532b5f5a-6cfb-4db4-b870-2554958e5d2c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 22/200000 [00:00<38:19, 86.97it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch = 0    loss = 5.855\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 20047/200000 [01:25<11:27, 261.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch = 20000    loss = 2.143\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 40033/200000 [02:43<10:05, 264.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch = 40000    loss = 0.931\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 60041/200000 [04:02<09:03, 257.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch = 60000    loss = 0.721\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 80025/200000 [05:21<07:59, 250.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch = 80000    loss = 0.675\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 100029/200000 [06:40<06:43, 247.75it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch = 100000    loss = 0.655\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 120030/200000 [07:59<05:08, 258.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch = 120000    loss = 0.643\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 140030/200000 [09:18<03:58, 251.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch = 140000    loss = 0.640\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 160025/200000 [10:36<02:33, 260.86it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch = 160000    loss = 0.635\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 180050/200000 [11:54<01:16, 259.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch = 180000    loss = 0.635\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200000/200000 [13:12<00:00, 252.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch = 200000    loss = 0.631\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "encoder = EncoderRNN(dataset.len_input()+2, 30)\n",
        "attn_decoder1 = AttnDecoderRNN(30, dataset.len_target()+2, dropout_p=0.1)\n",
        "\n",
        "encoder_optimizer = torch.optim.SGD(encoder.parameters(), lr=0.01)\n",
        "decoder_optimizer = torch.optim.SGD(attn_decoder1.parameters(), lr=0.01)\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "n_epochs = 200000 # количество эпох\n",
        "n = n_epochs//10\n",
        "np.random.seed(1000)\n",
        "training_pairs = np.random.randint(0, num_samples, size=n_epochs)\n",
        "loss_accumed = 0\n",
        "\n",
        "for epoch in tqdm(range(n_epochs)):\n",
        "\n",
        "    input_tensor, target_tensor = dataset[training_pairs[epoch]]\n",
        "    loss = train(input_tensor, target_tensor, encoder, attn_decoder1, encoder_optimizer, decoder_optimizer, criterion)\n",
        "    loss_accumed += loss\n",
        "\n",
        "    if epoch < 1:\n",
        "        print(f'\\nepoch = {epoch}    loss = {loss_accumed:.3f}')\n",
        "        loss_accumed = 0\n",
        "        continue\n",
        "\n",
        "    if epoch % n == 0:\n",
        "        print(f'\\nepoch = {epoch}    loss = {loss_accumed/n:.3f}')\n",
        "        loss_accumed = 0\n",
        "\n",
        "print(f'\\nepoch = {n_epochs}    loss = {loss_accumed/n:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8pqHE_mCXcJ"
      },
      "source": [
        "### Проверим результат:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "PjZJDohLXP2O"
      },
      "outputs": [],
      "source": [
        "output_data = pd.DataFrame(list(dataset.output_vocab2index.items()), columns=['word', 'token'])\n",
        "input_data = pd.DataFrame(list(dataset.input_vocab2index.items()), columns=['word', 'token'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "h_aU7PXtCoYE"
      },
      "outputs": [],
      "source": [
        "def reply(input_tensor, encoder, decoder, max_length=10):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size)\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[0]])\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    decoder_output, _, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "\n",
        "    return decoder_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AZgF2ueG1e1",
        "outputId": "165b4080-e9b7-4fcc-db62-5f26ebfd50e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input = I\n",
            "output = Понятно.\n",
            "target = Вижу.\n",
            "\n",
            "input = I'm\n",
            "output = Я\n",
            "target = Я\n",
            "\n",
            "input = Come\n",
            "output = Зайдите!\n",
            "target = Заходи.\n",
            "\n",
            "input = Smile.\n",
            "output = Улыбайтесь!\n",
            "target = Улыбнись.\n",
            "\n",
            "input = Fold\n",
            "output = Сложи\n",
            "target = Сложите\n",
            "\n",
            "input = Hit\n",
            "output = Бейте\n",
            "target = Ударь\n",
            "\n",
            "input = Eat\n",
            "output = Доедай.\n",
            "target = Доедай.\n",
            "\n",
            "input = Jump.\n",
            "output = Прыгайте!\n",
            "target = Прыгай!\n",
            "\n",
            "input = He\n",
            "output = Он\n",
            "target = Он\n",
            "\n",
            "input = Hold\n",
            "output = Замри!\n",
            "target = Замри!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "training_pairs = np.random.randint(0, num_samples, size=n_epochs)\n",
        "for i in range(10):\n",
        "    input_tensor, target_tensor = dataset[training_pairs[i]]\n",
        "    output = reply(input_tensor, encoder, attn_decoder1)\n",
        "    _, topi = output.topk(1)\n",
        "    print(f\"input = {input_data.loc[input_data['token']==input_tensor[0][0].item(), 'word'].item()}\")\n",
        "    print(f\"output = {output_data.loc[output_data['token']==topi.squeeze().detach().item(), 'word'].item()}\")\n",
        "    print(f\"target = {output_data.loc[output_data['token']==target_tensor[0][0].item(), 'word'].item()}\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Фреймворк PyTorch_ДЗ_9.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
